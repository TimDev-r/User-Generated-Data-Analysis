{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*UE Learning from User-generated Data, CP MMS, JKU Linz 2023*\n",
    "# Challenge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "from rec import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def KL(P: np.ndarray, Q: np.ndarray, eps: float = 1e-14):\n",
    "    '''\n",
    "    P - np.ndarray, probability distribution\n",
    "    Q - np.ndarray, probability distribution\n",
    "    eps - float, margin added to both distributions to avoid division by zero errors\n",
    "    returns - float, divergence of distributions P,Q\n",
    "    '''\n",
    "\n",
    "    kl = None\n",
    "\n",
    "    P = P + eps\n",
    "    Q = Q + eps\n",
    "    kl = float(0)\n",
    "    for i in range(len(P)):\n",
    "        kl += P[i]*np.log2(P[i]/Q[i])\n",
    "    kl = float(kl)\n",
    "\n",
    "    return kl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check if you handle zeros correctly (use \"eps\" parameter)\n",
    "P = np.array([0.3, 0.6, 0.1])\n",
    "Q = np.array([0.4, 0.6, 0.0])\n",
    "\n",
    "assert type(KL(P, Q)) == float\n",
    "assert np.isclose(KL(P, Q), 4.193995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def JSD(P: np.ndarray, Q: np.ndarray, eps: float = 1e-14):\n",
    "    '''\n",
    "    P - np.ndarray, probability distribution\n",
    "    Q - np.ndarray, probability distribution\n",
    "    eps - float, margin added to both distributions to avoid division by zero errors, parameter for KL\n",
    "    returns - float, divergence of distributions P,Q\n",
    "    '''\n",
    "\n",
    "    jsd = None\n",
    "    kl_pm,kl_qm = 0,0\n",
    "    P = P + eps\n",
    "    Q = Q + eps\n",
    "    M = 0.5*(P+Q)\n",
    "    \n",
    "\n",
    "    for i in range(len(P)):\n",
    "        kl_pm += P[i]*np.log2(P[i]/M[i])\n",
    "\n",
    "    for i in range(len(Q)):\n",
    "        kl_qm += Q[i]*np.log2(Q[i]/M[i])\n",
    "\n",
    "    jsd = 0.5*kl_qm + 0.5*kl_pm\n",
    "    jsd = float(jsd)\n",
    "\n",
    "\n",
    "    return jsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check if you handle zeros correctly (use \"eps\" parameter)\n",
    "P = np.array([0.3, 0.6, 0.1])\n",
    "Q = np.array([0.4, 0.6, 0.0])\n",
    "\n",
    "assert type(JSD(P, Q)) == float\n",
    "assert np.isclose(JSD(P, Q), 0.055170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# KL divergence compares a target distribution to a reference distribution and is NOT symmetric\n",
    "# JS divergence is symmetric -  you can exchange P and Q and get the same results\n",
    "# the following asserts check this behaviour\n",
    "P = np.array([0.3, 0.6, 0.1])\n",
    "Q = np.array([0.2, 0.3, 0.5])\n",
    "\n",
    "assert KL(P, Q) != KL(Q, P)\n",
    "assert JSD(P, Q) == JSD(Q, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Task \n",
    "\n",
    "Load the users, items and both the train interactions and test interactions\n",
    "from the **new version of the lfm dataset** provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read(dataset, file):\n",
    "    return pd.read_csv(dataset + '.' + file, sep='\\t')\n",
    "\n",
    "users = read(\"lfm-tiny\", 'user')\n",
    "items = read(\"lfm-tiny\", 'item')\n",
    "train_inters = read(\"lfm-tiny\", 'inter_train')\n",
    "test_inters = read(\"lfm-tiny\", 'inter_test')\n",
    "\n",
    "train_interaction_matrix = inter_matr_implicit(users=users, items=items, interactions=train_inters,\n",
    "                                               dataset_name=\"lfm-tiny\")\n",
    "test_interaction_matrix = inter_matr_implicit(users=users, items=items, interactions=test_inters,\n",
    "                                              dataset_name=\"lfm-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=int8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1194, 412)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_interaction_matrix, np.shape(train_interaction_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users' representations:\n",
      " [[ 0.01665131  0.00903522 -0.00468575 ... -0.10026957  0.03784116\n",
      "   0.01031858]\n",
      " [ 0.02998008  0.02846227  0.01030624 ... -0.01206406  0.01609656\n",
      "   0.01281369]\n",
      " [ 0.00741979  0.0062279   0.00487695 ...  0.02174137  0.00103163\n",
      "   0.01011269]\n",
      " ...\n",
      " [ 0.01529216  0.00133054  0.02999989 ...  0.04132464 -0.00366416\n",
      "  -0.00327995]\n",
      " [ 0.00348654 -0.00117236  0.0069645  ...  0.01838751 -0.01558518\n",
      "   0.01606245]\n",
      " [ 0.01739873 -0.02506171  0.01391198 ... -0.00953045  0.02599903\n",
      "   0.01115208]] \n",
      "\n",
      "items' representations:\n",
      " [[ 0.01100866 -0.00786847 -0.01056714 ... -0.16250542 -0.04366737\n",
      "   0.00145276]\n",
      " [ 0.05403607 -0.06191249 -0.07123008 ... -0.00702884  0.00445195\n",
      "  -0.0022016 ]\n",
      " [ 0.07569417  0.05281746  0.01061387 ... -0.0002195   0.00068732\n",
      "   0.00054193]\n",
      " ...\n",
      " [ 0.01295486 -0.02022103  0.00683831 ...  0.00607692  0.01221049\n",
      "  -0.02644329]\n",
      " [ 0.00534639 -0.00806501 -0.00417752 ... -0.00815688  0.01367933\n",
      "  -0.00288832]\n",
      " [ 0.00504318 -0.00849825  0.00681265 ... -0.0026571   0.0036718\n",
      "   0.00877125]] \n",
      "\n",
      "singular values: [15.68406651 13.59018363 11.02155791 10.13508811  9.90806667  9.5198534\n",
      "  9.4176381   8.94372135  8.52222636  8.42334411  8.34523613  8.18723578\n",
      "  8.12618714  7.89930023  7.82400747  7.68346761  7.62279763  7.48649743\n",
      "  7.45738188  7.30810386  7.16803077  7.1038648   7.09778535  7.01603204\n",
      "  6.90175638  6.8393935   6.80393944  6.64391486  6.60700173  6.59442981\n",
      "  6.53301107  6.44174803  6.37231168  6.31975175  6.2751338   6.24716847\n",
      "  6.21108794  6.17075844  6.06772629  5.98449966  5.97276848  5.89235788\n",
      "  5.88123342  5.84245973  5.83539164  5.77690954  5.74399972  5.65039609\n",
      "  5.62177152  5.5951964   5.54723498  5.51397649  5.48160628  5.44006489\n",
      "  5.39179759  5.30306254  5.28671647  5.26684436  5.25667925  5.18878696\n",
      "  5.15432727  5.12682241  5.11824716  5.07192152  5.04496135  5.00195877\n",
      "  4.99462293  4.96726695  4.96524335  4.94035648  4.90927222  4.87337131\n",
      "  4.84215504  4.83086416  4.79557567  4.76648173  4.73474534  4.69806623\n",
      "  4.67588265  4.64467407  4.60970234  4.58520662  4.57385606  4.56545248\n",
      "  4.53895276  4.51883045  4.48581178  4.44594146  4.43785196  4.41687297\n",
      "  4.36501434  4.3454773   4.32472137  4.31572902  4.30161086  4.29120422\n",
      "  4.25713747  4.24081132  4.23572602  4.20274758  4.17681862  4.14780411\n",
      "  4.11969675  4.11325036  4.10345591  4.08976029  4.0691383   4.04952776\n",
      "  4.00989402  3.99815858  3.98321256  3.95776117  3.94615035  3.91086026\n",
      "  3.89804317  3.88456305  3.87143846  3.84857327  3.83592729  3.81219398\n",
      "  3.79657272  3.77167206  3.7598571   3.75039728  3.73824966  3.72423686\n",
      "  3.70579193  3.69614038  3.68466956  3.67938257  3.63552962  3.62504956\n",
      "  3.6144716   3.59853686  3.58392767  3.57523593  3.54150635  3.53552465\n",
      "  3.5338355   3.52943489  3.51838266  3.49513532  3.47508948  3.46270392\n",
      "  3.44910739  3.43954354  3.43463189  3.41340916  3.39884984  3.39093601\n",
      "  3.38522954  3.37896895  3.3598583   3.34923702  3.34369811  3.33669313\n",
      "  3.32264281  3.30311375  3.29400293  3.28486323  3.28077612  3.26650242\n",
      "  3.24795356  3.22318551  3.2150918   3.20004621  3.19535414  3.19452387\n",
      "  3.17482205  3.16690738  3.16077296  3.13285959  3.12488544  3.11505125\n",
      "  3.10374868  3.09469007  3.09360193  3.07443342  3.05794366  3.04737207\n",
      "  3.0376618   3.02624913  3.0161594   3.00753644  3.00192411  2.98074871\n",
      "  2.97820704  2.96883312  2.95402743  2.94281726  2.9377074   2.92791025\n",
      "  2.90982357  2.9016979   2.8951445   2.89225341  2.87847281  2.87237036\n",
      "  2.86478314  2.8612874   2.84459896  2.83888264  2.8313561   2.80173047\n",
      "  2.79747768  2.78987235  2.77492033  2.77258928  2.75170146  2.7403382\n",
      "  2.73926798  2.73273969  2.72588945  2.71380586  2.70416689  2.69499747\n",
      "  2.67806561  2.66723933  2.660786    2.65411661  2.64681149  2.62887238\n",
      "  2.6246113   2.6162366   2.60190594  2.5982018   2.58380517  2.58046322\n",
      "  2.56922058  2.56082622  2.5468611   2.54302356  2.53329834  2.52590122\n",
      "  2.52355063  2.50726316  2.50466334  2.48758134  2.48027032  2.47229587\n",
      "  2.46304308  2.44957442  2.44302874  2.43683767  2.43283244  2.42351598\n",
      "  2.41408628  2.40628931  2.39526858  2.37071704  2.36764324  2.36101011\n",
      "  2.3502308   2.34546569  2.33680073  2.33176511  2.32401447  2.30890727\n",
      "  2.30534883  2.29367715  2.29024259  2.27897228  2.27788641  2.26634791\n",
      "  2.26300384  2.24522796  2.23465519  2.23040697  2.22503027  2.22006497\n",
      "  2.20874163  2.20304261  2.19679745  2.18968801  2.18636054  2.17008958\n",
      "  2.16467246  2.15080449  2.14608141  2.13625263  2.13079989  2.12478931\n",
      "  2.1146575   2.1087275   2.10559774  2.09813493  2.0870203   2.08390875\n",
      "  2.08265739  2.0648809   2.06127555  2.05044851  2.04005596  2.02400031\n",
      "  2.02209576  2.00414619  1.99989896  1.99743063  1.99414959  1.9875946\n",
      "  1.98418821  1.97652666  1.96429792  1.95893708  1.95174628  1.94748449\n",
      "  1.93479695  1.93123886  1.92204639  1.91213716  1.90643346  1.90281881\n",
      "  1.89077069  1.8752317   1.87025455  1.86920152  1.86270665  1.84697718\n",
      "  1.83883049  1.83138619  1.82725624  1.81769329  1.81044866  1.80596483\n",
      "  1.78906393  1.78731151  1.77962099  1.76857235  1.75959143  1.75139907\n",
      "  1.74256244  1.73342023  1.73031138  1.72065547  1.70258767  1.69848047\n",
      "  1.696356    1.685956    1.67831179  1.66764046  1.65571127  1.65001384\n",
      "  1.64716795  1.63964462  1.6376066   1.62929533  1.61354164  1.60294662\n",
      "  1.59697432  1.59147084  1.5883491   1.57902572  1.56869198  1.56206015\n",
      "  1.54578247  1.54017692  1.52998243  1.52014499  1.51193011  1.50359818\n",
      "  1.4884592   1.48417361  1.48053225  1.46915683  1.45597926  1.45139036\n",
      "  1.44137589  1.42707152  1.41879086  1.41627318  1.3999824   1.38999141\n",
      "  1.38514522  1.3705545   1.36617964  1.36115903  1.3500018   1.33673692\n",
      "  1.33338392  1.32637004  1.31846962  1.30470486  1.29192856  1.29054667\n",
      "  1.27156899  1.2670467   1.25785847  1.243178    1.23165549  1.21230443\n",
      "  1.20387727  1.19523653  1.17475422  1.16566232  1.1574008   1.14887882\n",
      "  1.10902789  1.10044073  1.08810245  1.08099149  1.02922602  1.01286768\n",
      "  1.00645037  0.97808802  0.95673628  0.92940709  0.90797675  0.88016069\n",
      "  0.87175439  0.82602654  0.66606597  0.63710098] \n",
      "\n",
      "412\n",
      "reconstructed matrix\n",
      " [[-1.64798730e-16 -5.25621213e-16  1.00000000e+00 ...  2.23779328e-16\n",
      "   4.16333634e-17 -2.46330734e-16]\n",
      " [ 2.71917905e-16 -1.49469467e-15 -6.66567496e-16 ... -2.35922393e-16\n",
      "  -3.31332184e-16  4.92661467e-16]\n",
      " [-7.97972799e-17  1.33920652e-15 -1.07010754e-15 ... -4.40619763e-16\n",
      "  -3.67761377e-16 -2.28116137e-16]\n",
      " ...\n",
      " [-5.95010152e-16  5.12610787e-16 -1.49663268e-15 ... -1.90819582e-17\n",
      "   1.00613962e-16  6.22332047e-17]\n",
      " [-8.32667268e-17 -5.10008702e-16 -4.51028104e-16 ...  3.41740525e-16\n",
      "   4.67941658e-16  2.80157841e-16]\n",
      " [ 3.68411898e-16  1.00000000e+00 -3.78213086e-15 ...  1.02782366e-16\n",
      "  -1.63064007e-16  5.46437895e-17]] \n",
      "\n",
      "reconstructed matrix (rounded)\n",
      " [[-0. -0.  1. ...  0.  0. -0.]\n",
      " [ 0. -0. -0. ... -0. -0.  0.]\n",
      " [-0.  0. -0. ... -0. -0. -0.]\n",
      " ...\n",
      " [-0.  0. -0. ... -0.  0.  0.]\n",
      " [-0. -0. -0. ...  0.  0.  0.]\n",
      " [ 0.  1. -0. ...  0. -0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# we set 'full_matrices' to 'False' for Thin SVD\n",
    "U, s, Vh = np.linalg.svd(train_interaction_matrix, full_matrices=False)\n",
    "\n",
    "# let's quickly construct the matrix back to make sure everything works\n",
    "res = (U @ np.diag(s)) @ Vh\n",
    "\n",
    "print('users\\' representations:\\n', U, '\\n')\n",
    "print('items\\' representations:\\n', Vh.T, '\\n')  # Transposing to have first dimension correspond to items\n",
    "print('singular values:', s, '\\n')\n",
    "print(len(s))\n",
    "print('reconstructed matrix\\n', res, '\\n')\n",
    "print('reconstructed matrix (rounded)\\n', res.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/\n",
    "/\n",
    "/\n",
    "**Now let's check if matrices are identical**\n",
    "/\n",
    "/\n",
    "/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "otv = np.isclose(train_interaction_matrix,res.round())\n",
    "display(otv)\n",
    "print(np.count_nonzero(otv == False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having https://www.sciencedirect.com/science/article/pii/S2772415822000244 as a reference, we can sum up singular valuse(variances), and retain the first **K** singular values such that the cumulative percentage of the total variance is bigger than a threshold value between 70-90%. Let's take 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variances sum =  1361.8689574779498\n",
      "[15.68406651 13.59018363 11.02155791 10.13508811  9.90806667  9.5198534\n",
      "  9.4176381   8.94372135  8.52222636  8.42334411  8.34523613  8.18723578\n",
      "  8.12618714  7.89930023  7.82400747  7.68346761  7.62279763  7.48649743\n",
      "  7.45738188  7.30810386  7.16803077  7.1038648   7.09778535  7.01603204\n",
      "  6.90175638  6.8393935   6.80393944  6.64391486  6.60700173  6.59442981\n",
      "  6.53301107  6.44174803  6.37231168  6.31975175  6.2751338   6.24716847\n",
      "  6.21108794  6.17075844  6.06772629  5.98449966  5.97276848  5.89235788\n",
      "  5.88123342  5.84245973  5.83539164  5.77690954  5.74399972  5.65039609\n",
      "  5.62177152  5.5951964   5.54723498  5.51397649  5.48160628  5.44006489\n",
      "  5.39179759  5.30306254  5.28671647  5.26684436  5.25667925  5.18878696\n",
      "  5.15432727  5.12682241  5.11824716  5.07192152  5.04496135  5.00195877\n",
      "  4.99462293  4.96726695  4.96524335  4.94035648  4.90927222  4.87337131\n",
      "  4.84215504  4.83086416  4.79557567  4.76648173  4.73474534  4.69806623\n",
      "  4.67588265  4.64467407  4.60970234  4.58520662  4.57385606  4.56545248\n",
      "  4.53895276  4.51883045  4.48581178  4.44594146  4.43785196  4.41687297\n",
      "  4.36501434  4.3454773   4.32472137  4.31572902  4.30161086  4.29120422\n",
      "  4.25713747  4.24081132  4.23572602  4.20274758  4.17681862  4.14780411\n",
      "  4.11969675  4.11325036  4.10345591  4.08976029  4.0691383   4.04952776\n",
      "  4.00989402  3.99815858  3.98321256  3.95776117  3.94615035  3.91086026\n",
      "  3.89804317  3.88456305  3.87143846  3.84857327  3.83592729  3.81219398\n",
      "  3.79657272  3.77167206  3.7598571   3.75039728  3.73824966  3.72423686\n",
      "  3.70579193  3.69614038  3.68466956  3.67938257  3.63552962  3.62504956\n",
      "  3.6144716   3.59853686  3.58392767  3.57523593  3.54150635  3.53552465\n",
      "  3.5338355   3.52943489  3.51838266  3.49513532  3.47508948  3.46270392\n",
      "  3.44910739  3.43954354  3.43463189  3.41340916  3.39884984  3.39093601\n",
      "  3.38522954  3.37896895  3.3598583   3.34923702  3.34369811  3.33669313\n",
      "  3.32264281  3.30311375  3.29400293  3.28486323  3.28077612  3.26650242\n",
      "  3.24795356  3.22318551  3.2150918   3.20004621  3.19535414  3.19452387\n",
      "  3.17482205  3.16690738  3.16077296  3.13285959  3.12488544  3.11505125\n",
      "  3.10374868  3.09469007  3.09360193  3.07443342  3.05794366  3.04737207\n",
      "  3.0376618   3.02624913  3.0161594   3.00753644  3.00192411  2.98074871\n",
      "  2.97820704  2.96883312  2.95402743  2.94281726  2.9377074   2.92791025\n",
      "  2.90982357  2.9016979   2.8951445   2.89225341  2.87847281  2.87237036\n",
      "  2.86478314  2.8612874   2.84459896  2.83888264  2.8313561   2.80173047\n",
      "  2.79747768  2.78987235  2.77492033  2.77258928  2.75170146  2.7403382\n",
      "  2.73926798  2.73273969  2.72588945  2.71380586  2.70416689  2.69499747\n",
      "  2.67806561  2.66723933  2.660786    2.65411661  2.64681149  2.62887238\n",
      "  2.6246113   2.6162366   2.60190594  2.5982018   2.58380517  2.58046322\n",
      "  2.56922058  2.56082622  2.5468611   2.54302356  2.53329834  2.52590122\n",
      "  2.52355063  2.50726316  2.50466334  2.48758134  2.48027032  2.47229587\n",
      "  2.46304308  2.44957442  2.44302874  2.43683767  2.43283244  2.42351598\n",
      "  2.41408628  2.40628931  2.39526858  2.37071704  2.36764324  2.36101011]\n"
     ]
    }
   ],
   "source": [
    "var_sum = np.sum(s)\n",
    "print(\"variances sum = \",var_sum)\n",
    "\n",
    "# Calculate the cumulative sum array of the variances array\n",
    "cumulative_sum = np.cumsum(s)\n",
    "#print(cumulative_sum)\n",
    "\n",
    "# Find the index where the cumulative sum exceeds or equals the target sum\n",
    "index = np.argmax(cumulative_sum >= 0.80*var_sum)\n",
    "\n",
    "# Select the elements from the sorted array up to the found index\n",
    "selected_elements = s[:index+1]\n",
    "print(selected_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reconstructed interaction matrix with f = '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "', truncated:\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0., -0.,  1., ...,  0.,  0., -0.],\n",
       "       [-0., -0., -0., ..., -0.,  0.,  0.],\n",
       "       [-0.,  0.,  0., ..., -0., -0.,  0.],\n",
       "       ...,\n",
       "       [ 0., -0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0., -0., -0., ...,  0.,  0.,  0.],\n",
       "       [-0.,  1.,  0., ..., -0.,  0.,  0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1194, 412)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "u,v = svd_decompose(train_interaction_matrix,len(selected_elements))\n",
    "# let's quickly construct the matrix back to make sure everything works\n",
    "f = len(selected_elements)\n",
    "cut_array = u @ v.T\n",
    "display('reconstructed interaction matrix with f = ', f, ', truncated:\\n', cut_array.round(),np.shape(cut_array))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Checking if matrices are identical now**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "272  missmathces throughout composed matrix  491928 , which is  0.00055 %\n"
     ]
    }
   ],
   "source": [
    "otv = np.isclose(train_interaction_matrix,cut_array.round())\n",
    "display(otv)\n",
    "print()\n",
    "print(np.count_nonzero(otv == False), \" missmathces throughout composed matrix \",\n",
    "      np.shape(cut_array)[0]*np.shape(cut_array)[1],\n",
    "     \", which is \", '%.5f'%(np.count_nonzero(otv == False)/(np.shape(cut_array)[0]*np.shape(cut_array)[1])),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part  : Iterative Matrix Factorization with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "\n",
    "    def __init__(self, n_users: int, n_items: int, n_factors: int):\n",
    "        \"\"\"\n",
    "        n_users - int - number of users.\n",
    "        n_items - int - number of items.\n",
    "        n_factors - int - dimensionality of the latent space.\n",
    "        \"\"\"\n",
    "\n",
    "        super(MF, self).__init__()\n",
    "\n",
    "        self.embedding_user = nn.Embedding(n_users, n_factors)\n",
    "        self.embedding_item = nn.Embedding(n_items, n_factors)\n",
    "\n",
    "    def forward(self, user: torch.Tensor, item: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        We allow for some flexibility giving lists of ids as inputs:\n",
    "        if the training data is small we can deal with it in a single forward pass,\n",
    "        otherwise we could fall back to mini-batches, limiting users and items we pass\n",
    "        every time.\n",
    "        \n",
    "        user - torch.Tensor - user_ids.\n",
    "        item - torch.Tensor - item_ids.\n",
    "        \n",
    "        returns - torch.Tensor - Reconstructed Interaction matrix of shape (n_users, n_items).\n",
    "        \"\"\"\n",
    "        \n",
    "        u = self.embedding_user(user)\n",
    "        v = self.embedding_item(item)\n",
    "        interaction_matrix = u @ v.T\n",
    "        reconstructed_matrix = interaction_matrix\n",
    "        #reconstructed_matrix = torch.relu(interaction_matrix)  # Adding ReLU activation\n",
    "\n",
    "        return reconstructed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    logits - torch.Tensor - output of model.\n",
    "    labels - torch.Tensor - labels / interaction matrix model should learn to reconstruct.\n",
    "    \n",
    "    returns - torch.Tensor - BCELoss over all logits and labels.\n",
    "    \"\"\"\n",
    "    loss = None\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION.\n",
    "    \n",
    "    bce_loss = nn.BCELoss()\n",
    "    act_output = nn.Sigmoid()(logits)\n",
    "    loss_output = bce_loss(act_output, labels)\n",
    "    loss = loss_output\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, train_data_inter: np.ndarray, epochs: int, optimizer, loss_func) -> list:\n",
    "    \"\"\"\n",
    "    model - nn.Module - torch module to train.\n",
    "    train_data_inter - np.ndarray - interaction matrix of the training data.\n",
    "    epochs - int - number of epochs to perform.\n",
    "    optimizer - optim - optimizer for training.\n",
    "    loss_func - loss function for training.\n",
    "    \n",
    "    returns - list - list of loss values over all epochs.\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    user_ids = torch.Tensor(list(range(train_data_inter.shape[0]))).long()\n",
    "    item_ids = torch.Tensor(list(range(train_data_inter.shape[1]))).long()\n",
    "    y = torch.Tensor(train_data_inter).long()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_hat = model(user_ids, item_ids)\n",
    "\n",
    "        loss = loss_func(y_hat.unsqueeze(0).float(), y.unsqueeze(0).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 50 == 0:\n",
    "            print(\"Loss \", e, \": \", loss.item())\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change the seed.\n",
    "torch.manual_seed(1234)\n",
    "rnd.seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "# TODO: YOUR IMPLEMENATION.\n",
    "# Initialize the model and optimizer as prescribed\n",
    "model = MF(1194,412,252)\n",
    "\"\"\"\n",
    "        n_users - int - number of users.\n",
    "        n_items - int - number of items.\n",
    "        n_factors - int - dimensionality of the latent space.\n",
    "\"\"\"\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0 :  17.254154205322266\n",
      "Loss  50 :  15.833192825317383\n",
      "Loss  100 :  13.722026824951172\n",
      "Loss  150 :  10.310229301452637\n",
      "Loss  200 :  6.272189140319824\n",
      "Loss  250 :  3.2926218509674072\n",
      "Loss  300 :  1.67078697681427\n",
      "Loss  350 :  0.9454523921012878\n",
      "Loss  400 :  0.6346049904823303\n",
      "Loss  450 :  0.47964295744895935\n",
      "Loss  500 :  0.39493435621261597\n",
      "Loss  550 :  0.34289634227752686\n",
      "Loss  600 :  0.30419012904167175\n",
      "Loss  650 :  0.2747049331665039\n",
      "Loss  700 :  0.2512243688106537\n",
      "Loss  750 :  0.23089730739593506\n",
      "Loss  800 :  0.21569620072841644\n",
      "Loss  850 :  0.20231235027313232\n",
      "Loss  900 :  0.1921001672744751\n",
      "Loss  950 :  0.18474797904491425\n",
      "Loss  1000 :  0.178968608379364\n",
      "Loss  1050 :  0.17430005967617035\n",
      "Loss  1100 :  0.17070886492729187\n",
      "Loss  1150 :  0.16718915104866028\n",
      "Loss  1200 :  0.16419681906700134\n",
      "Loss  1250 :  0.1617870181798935\n",
      "Loss  1300 :  0.1589946746826172\n",
      "Loss  1350 :  0.1578778177499771\n",
      "Loss  1400 :  0.15655966103076935\n",
      "Loss  1450 :  0.15535816550254822\n",
      "Loss  1500 :  0.15369823575019836\n",
      "Loss  1550 :  0.1527414172887802\n",
      "Loss  1600 :  0.15184570848941803\n",
      "Loss  1650 :  0.15082548558712006\n",
      "Loss  1700 :  0.15035387873649597\n",
      "Loss  1750 :  0.14919744431972504\n",
      "Loss  1800 :  0.14859609305858612\n",
      "Loss  1850 :  0.1480439454317093\n",
      "Loss  1900 :  0.14716942608356476\n",
      "Loss  1950 :  0.14681005477905273\n"
     ]
    }
   ],
   "source": [
    "loss_model = train(model=model,\n",
    "                       train_data_inter=train_interaction_matrix,\n",
    "                       epochs=2000,\n",
    "                       optimizer=optimizer,\n",
    "                       loss_func=compute_loss)\n",
    "\n",
    "#assert len(loss_model) == 1000, \"Loss should have 1000 elements, one for each epoch.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_model, label=\"252\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"BCE Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations with the trained Factorization Model\n",
    "\n",
    "Let's write a function that recommends topK items to a user, whose id is given, using the trained model.\n",
    "Our recommendation should be done in a fashion similar to *svd_recommend*: score items based the corresponding embeddings. We do not consider items already seen by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itMF_recommend(user_id: int, seen_item_ids: list, model=None, topK=10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Recommend with the trained model to selected users\n",
    "    \n",
    "    user_id - int - id of target user.\n",
    "    seen_item_ids - list[list[int]] ids of items already seen by the users (to exclude from recommendation)\n",
    "    model - trainted factorization model to use for scoring\n",
    "    topK - number of recommendations per user to be returned\n",
    "    \n",
    "    returns - np.ndarray - np.ndarray - list of ids of recommended items in the order of descending score\n",
    "                           use -1 as a place holder item index, when it is impossible to recommend topK items\n",
    "    \"\"\"\n",
    "    recs = None\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        state_dict = model.state_dict()\n",
    "        U = state_dict['embedding_user.weight'].detach().numpy()\n",
    "        V = state_dict['embedding_item.weight'].detach().numpy()\n",
    "\n",
    "        rec = np.dot(U[user_id,:], V.T)\n",
    "    \n",
    "        for i in range(len(rec)):\n",
    "            if i in seen_item_ids[0]:\n",
    "                rec[i] = -1\n",
    "\n",
    "        otv = np.argsort(rec)[::-1]\n",
    "        otv = np.append(otv[:topK], [-1] * (topK - len(otv[:topK])))\n",
    "\n",
    "    return np.array(otv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part  : Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndcg_score(predictions: np.ndarray, test_interaction_matrix: np.ndarray, topK=10) -> float:\n",
    "    \"\"\"\n",
    "    predictions - np.ndarray - predictions of the recommendation algorithm for each user.\n",
    "    test_interaction_matrix - np.ndarray - test interaction matrix for each user.\n",
    "    topK - int - topK recommendations should be evaluated.\n",
    "    \n",
    "    returns - average ndcg score over all users.\n",
    "    \"\"\"\n",
    "    score = None\n",
    "    \n",
    "    # TODO: YOUR IMPLEMENTATION.\n",
    "    ndcg_scores = []\n",
    "    num_users = predictions.shape[0]\n",
    "\n",
    "    for i in range(num_users):\n",
    "        # Get the topK recommendations for the i-th user\n",
    "        topk_items = predictions[i][:topK]\n",
    "        \n",
    "        # Get the held-out items for the i-th user\n",
    "        held_out_items = np.where(test_interaction_matrix[i] == 1)[0]\n",
    "        \n",
    "        # Compute the ideal DCG for the i-th user\n",
    "        ideal_dcg = 0.0\n",
    "        for j in range(min(topK, len(held_out_items))):\n",
    "            if j == 0:\n",
    "                    ideal_dcg += 1.0\n",
    "            else:\n",
    "                ideal_dcg += 1.0 / np.log2(j + 2)\n",
    "        \n",
    "        # Compute the actual DCG for the i-th user\n",
    "        dcg = 0.0\n",
    "        for j, item in enumerate(topk_items):\n",
    "            if item in held_out_items:\n",
    "                if j == 0:\n",
    "                    dcg += 1.0\n",
    "                else:\n",
    "                    dcg += 1.0 / np.log2(j + 2)\n",
    "\n",
    "        # Compute the nDCG score for the i-th user\n",
    "        if ideal_dcg > 0:\n",
    "            ndcg = dcg / ideal_dcg\n",
    "        else:\n",
    "            ndcg = 0.0\n",
    "        \n",
    "        ndcg_scores.append(ndcg)\n",
    "\n",
    "    # Compute the average nDCG score over all users\n",
    "    score = np.mean(ndcg_scores)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_predict = {\n",
    "    #interaction matrix\n",
    "    \"train_inter\": train_interaction_matrix,\n",
    "    #topK parameter used for all algorithms\n",
    "    \"top_k\": 10,\n",
    "    #specific parameters for all algorithms\n",
    "    \"recommenders\": {\n",
    "        \"SVD\": {\n",
    "            \"n_factors\": len(selected_elements)\n",
    "        },\n",
    "        \"Iterative Matrix Factorization\": {\n",
    "            \"n_factors\": len(selected_elements)\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_for_algorithms(config: dict) -> dict:\n",
    "    \"\"\"\n",
    "    config - dict - configuration as defined above\n",
    "\n",
    "    returns - dict - already predefined below with name \"rec_dict\"\n",
    "    \"\"\"\n",
    "\n",
    "    # get the top_k parameter from the config\n",
    "    top_k = config[\"top_k\"]\n",
    "    \n",
    "    #use this structure to return results\n",
    "    rec_dict = {\"recommenders\": {\n",
    "        \"SVD\": {\n",
    "            #Add your predictions here\n",
    "            \"predictions\": np.empty((0,top_k ))\n",
    "        },\n",
    "        # \"Iterative Matrix Factorization\": {\n",
    "        #     \"predictions\": np.empty((0,top_k ))\n",
    "        # },\n",
    "    }}\n",
    "    \n",
    "    # get train_interaction_matrix from the config\n",
    "    train_interaction_matrix = config[\"train_inter\"]\n",
    "\n",
    "    # get recommenders from the config\n",
    "    recommenders = config['recommenders']\n",
    "    \n",
    "    #SVD\n",
    "    n_factors = recommenders[\"SVD\"][\"n_factors\"]\n",
    "    U, V = u,v\n",
    "        \n",
    "    #Iterative Matrix Factorization\n",
    "    # n_neighbours = recommenders[\"ItemKNN\"][\"n_neighbours\"]\n",
    "        \n",
    "    for i in range(train_interaction_matrix.shape[0]):\n",
    "        seen_list = np.where(train_interaction_matrix[i] != 0)\n",
    "        rec_dict['recommenders']['SVD']['predictions'] = np.vstack([rec_dict['recommenders']['SVD']['predictions'],svd_recommend_to_list(i,seen_list,U,V,top_k)])\n",
    "        #rec_dict['recommenders']['Iterative Matrix Factorization']['predictions'] = np.vstack([rec_dict['recommenders']['Iterative Matrix Factorization']['predictions'],recTopK(train_interaction_matrix,i,top_k,n_neighbours)])\n",
    "\n",
    "\n",
    "\n",
    "    return rec_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = get_recommendations_for_algorithms(config_predict)\n",
    "\n",
    "assert \"SVD\" in recommendations[\"recommenders\"] and \"predictions\" in recommendations[\"recommenders\"][\"SVD\"]\n",
    "assert isinstance(recommendations[\"recommenders\"][\"SVD\"][\"predictions\"], np.ndarray)\n",
    "# assert \"ItemKNN\" in recommendations[\"recommenders\"] and \"predictions\" in recommendations[\"recommenders\"][\"ItemKNN\"]\n",
    "# assert isinstance(recommendations[\"recommenders\"][\"ItemKNN\"][\"predictions\"], np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_test = {\n",
    "    \"top_k\": 10,\n",
    "    \"test_inter\": test_interaction_matrix,\n",
    "    \"recommenders\": {}  # here you can access the recommendations from get_recommendations_for_algorithms\n",
    "\n",
    "}\n",
    "# add dictionary with recommendations to config dictionary\n",
    "config_test.update(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithms(config: dict) -> dict:\n",
    "    \"\"\"\n",
    "    config - dict - configuration as defined above\n",
    "\n",
    "    returns - dict - { Recommender Key from input dict: { \"ndcg\": float - ndcg from evaluation for this recommender} }\n",
    "    \"\"\"\n",
    "\n",
    "    metrics = {\n",
    "        \"SVD\": {\n",
    "        },\n",
    "        # \"Iterative Matrix Factorization\": {\n",
    "        # },\n",
    "    }\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION.\n",
    "    \n",
    "    top_k = config['top_k']\n",
    "    test_interaction_matrix = config['test_inter']\n",
    "    SVD = config['recommenders']['SVD']['predictions']\n",
    "    #ItemKNN = config['recommenders']['Iterative Matrix Factorization']['predictions']\n",
    "\n",
    "\n",
    "    metrics['SVD']['ndcg'] = get_ndcg_score(SVD, test_interaction_matrix, top_k)\n",
    "    #metrics['Iterative Matrix Factorization']['ndcg'] = get_ndcg_score(ItemKNN,test_interaction_matrix, top_k)\n",
    "\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD ndcg: 0.023616170887646743\n"
     ]
    }
   ],
   "source": [
    "evaluations = evaluate_algorithms(config_test)\n",
    "\n",
    "for recommender in evaluations.keys():\n",
    "    print(f\"{recommender} ndcg: {evaluations[recommender]['ndcg']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
